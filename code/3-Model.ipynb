{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b4dc9e4-1f9f-4383-b27b-3c1dd8c9f925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Further analysis on filtered_email_no_vendors and public_domain_df to identify the true positive\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3383b19-f6c9-4a45-aae4-664dd2161d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    if pd.isnull(text):  # Handle missing values\n",
    "        return \"\"\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text.lower())  # Remove special characters and numbers\n",
    "    words = word_tokenize(text)  # Tokenize text\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word not in stopwords.words('english')]  # Remove stopwords and lemmatize\n",
    "    return \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1398af2-5066-4c20-88a8-39902afa4782",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = pd.read_pickle('../data/combined_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8ca15b3-55dc-4e47-a396-3dd66bd1220c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to the email content\n",
    "combined_data['cleaned_email'] = combined_data['content'].map(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0203e4a6-4024-4b88-9e9c-fe5e52e3271e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Calculate sentiment scores\n",
    "combined_data['sentiment_score'] = combined_data['cleaned_email'].apply(lambda x: sia.polarity_scores(x)['compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "357a1e8f-a150-406d-a62a-019b3f4a6385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sensitive keywords\n",
    "sensitive_keywords = [\n",
    "    'password', 'confidential', 'secret', 'token', 'login', 'access',\n",
    "    'invoice', 'payment', 'tax', 'contract', 'NDA', 'urgent',\n",
    "    'link', 'click', 'phishing', 'SSN', 'ID number', 'personal',\n",
    "    'blueprint', 'source code', 'repository', 'algorithm',\n",
    "    'private', 'delete this', 'keep this secret', 'burn after reading']\n",
    "\n",
    "# Keyword detection function\n",
    "def detect_keywords(content):\n",
    "    return any(keyword in content for keyword in sensitive_keywords)\n",
    "\n",
    "# Add keyword-based threat detection\n",
    "combined_data['keyword_threat'] = combined_data['cleaned_email'].apply(detect_keywords)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
