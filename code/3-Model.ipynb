{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b4dc9e4-1f9f-4383-b27b-3c1dd8c9f925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Further analysis on filtered_email_no_vendors and public_domain_df to identify the true positive\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split , GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score ,confusion_matrix, \\\n",
    "ConfusionMatrixDisplay,roc_auc_score, precision_recall_curve ,roc_auc_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3383b19-f6c9-4a45-aae4-664dd2161d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    if pd.isnull(text):  # Handle missing values\n",
    "        return \"\"\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text.lower())  # Remove special characters and numbers\n",
    "    words = word_tokenize(text)  # Tokenize text\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word not in stopwords.words('english')]  # Remove stopwords and lemmatize\n",
    "    return \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1398af2-5066-4c20-88a8-39902afa4782",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = pd.read_pickle('../data/combined_data.pkl')\n",
    "#combined_data = pd.read_pickle('../data/final_balanced_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8ca15b3-55dc-4e47-a396-3dd66bd1220c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to the email content\n",
    "combined_data['cleaned_email'] = combined_data['content'].map(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0203e4a6-4024-4b88-9e9c-fe5e52e3271e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Calculate sentiment scores\n",
    "combined_data['sentiment_score'] = combined_data['cleaned_email'].apply(lambda x: sia.polarity_scores(x)['compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "357a1e8f-a150-406d-a62a-019b3f4a6385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sensitive keywords list\n",
    "sensitive_keywords = [\n",
    "    # General sensitive terms\n",
    "    'password', 'confidential', 'secret', 'token', 'login', 'access',\n",
    "    'invoice', 'payment', 'tax', 'contract', 'NDA', 'urgent', 'credentials',\n",
    "    'restricted', 'classified', 'proprietary', 'secure', 'encrypted',\n",
    "    \n",
    "    # Phishing and malicious intent\n",
    "    'link', 'click', 'phishing', 'malware', 'attachment', 'download', 'verify', 'authentication', 'reset',\n",
    "    'security breach', 'unauthorized', 'exposure', 'compromise', 'hack', 'exploit',\n",
    "\n",
    "    # Personal information\n",
    "    'SSN', 'ID number', 'passport', 'driverâ€™s license', 'address', 'bank account', 'credit card', \n",
    "    'personal', 'medical', 'insurance', 'privacy',\n",
    "\n",
    "    # Technical terms\n",
    "    'blueprint', 'source code', 'repository', 'algorithm', 'intellectual property', 'prototype', 'specification',\n",
    "    'server', 'database', 'API', 'framework', 'architecture', 'pipeline',\n",
    "\n",
    "    # Urgent or secretive phrases\n",
    "    'private', 'delete this', 'keep this secret', 'burn after reading', 'for your eyes only', \n",
    "    'do not share', 'immediate attention', 'asap', 'strictly confidential',\n",
    "\n",
    "    # Financial and operational terms\n",
    "    'wire transfer', 'invoice', 'ledger', 'audit', 'compliance', 'budget', 'expense', 'profit', \n",
    "    'margin', 'forecast', 'valuation', 'merger', 'acquisition',\n",
    "\n",
    "    # Industry-specific terms (customize as needed)\n",
    "    'trade secret','contract negotiation', 'strategic plan', 'market analysis', \n",
    "\n",
    "    # Additional potential triggers\n",
    "    'fraud', 'scam', 'deceptive', 'embezzlement', 'money laundering', 'corruption'\n",
    "]\n",
    "\n",
    "def detect_keywords(content):\n",
    "    return any(keyword in content for keyword in sensitive_keywords)\n",
    "\n",
    "#keyword-based threat detection\n",
    "combined_data['keyword_threat'] = combined_data['cleaned_email'].apply(detect_keywords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c238e010-b435-4d95-b97d-7af8832a983b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keyword_threat\n",
       "False    12853\n",
       "True      2651\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data['keyword_threat'].value_counts()\n",
    "#About 18% of the dataset was flagged as containing potential threats based on the keyword list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9dd84df-1b8f-4d4d-a922-89e52e12f8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anomaly detection: High positive sentiment or sensitive keywords to get the higher data \n",
    "combined_data['anomaly'] = (combined_data['sentiment_score'] > 0.8) | combined_data['keyword_threat']\n",
    "\n",
    "# Investigate anomalies\n",
    "anomalous_emails = combined_data[combined_data['anomaly']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c71c477-7f87-490e-8476-53baf13c154e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "anomaly\n",
       "False    10638\n",
       "True      4866\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data['anomaly'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9bd702-0b55-47e4-b32e-1369e4c3eaa3",
   "metadata": {},
   "source": [
    "## Content Analyst using NPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb158cba-23c9-417c-a1ba-2f2dcb69fe1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user', 'content', 'num_recipients', 'hour', 'day_of_week',\n",
       "       'attachments', 'size', 'threat_flag', 'cleaned_email',\n",
       "       'sentiment_score', 'keyword_threat', 'anomaly'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7eafdd9-ae75-4dea-a200-b734fefdd85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Target\n",
    "y = combined_data['threat_flag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ddbe302-89a9-40bf-86ba-be1fee51ec5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>content</th>\n",
       "      <th>num_recipients</th>\n",
       "      <th>hour</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>attachments</th>\n",
       "      <th>size</th>\n",
       "      <th>threat_flag</th>\n",
       "      <th>cleaned_email</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>keyword_threat</th>\n",
       "      <th>anomaly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABC0174</td>\n",
       "      <td>gold negotiating 13 vice entry coach memorial ...</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>19677</td>\n",
       "      <td>True</td>\n",
       "      <td>gold negotiating vice entry coach memorial mid...</td>\n",
       "      <td>0.7096</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABC0174</td>\n",
       "      <td>future always planets poorer jupiters only soo...</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>23739</td>\n",
       "      <td>True</td>\n",
       "      <td>future always planet poorer jupiter soon specu...</td>\n",
       "      <td>-0.6249</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABC0174</td>\n",
       "      <td>100 bruins eight 1997 intensive fan reprimande...</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>25277</td>\n",
       "      <td>True</td>\n",
       "      <td>bruin eight intensive fan reprimanded corey mv...</td>\n",
       "      <td>0.8402</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABC0174</td>\n",
       "      <td>nhls 01 season teammate home minnesota win str...</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>40514</td>\n",
       "      <td>True</td>\n",
       "      <td>nhls season teammate home minnesota win streng...</td>\n",
       "      <td>0.8271</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABC0174</td>\n",
       "      <td>naturally formed nuclei rising hours york expe...</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>20614</td>\n",
       "      <td>True</td>\n",
       "      <td>naturally formed nucleus rising hour york expe...</td>\n",
       "      <td>-0.0258</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15499</th>\n",
       "      <td>RVC0232</td>\n",
       "      <td>substantial last not not 120 received recover ...</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>76284</td>\n",
       "      <td>False</td>\n",
       "      <td>substantial last received recover enacted scal...</td>\n",
       "      <td>0.4939</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15500</th>\n",
       "      <td>KAT0489</td>\n",
       "      <td>20 horizontally morning left inversion radiate...</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>21608</td>\n",
       "      <td>False</td>\n",
       "      <td>horizontally morning left inversion radiated l...</td>\n",
       "      <td>0.5677</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15501</th>\n",
       "      <td>RGN0408</td>\n",
       "      <td>led regarded personal low man smashing lot par...</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>27696</td>\n",
       "      <td>False</td>\n",
       "      <td>led regarded personal low man smashing lot par...</td>\n",
       "      <td>-0.5574</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15502</th>\n",
       "      <td>MAE0331</td>\n",
       "      <td>have ukraine be pron money terminally more fre...</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32210</td>\n",
       "      <td>False</td>\n",
       "      <td>ukraine pron money terminally fresh father goo...</td>\n",
       "      <td>0.7269</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15503</th>\n",
       "      <td>IYB0918</td>\n",
       "      <td>offices inch alec load 1999 i delaware birthda...</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28077</td>\n",
       "      <td>False</td>\n",
       "      <td>office inch alec load delaware birthday freedo...</td>\n",
       "      <td>0.5106</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15504 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          user                                            content  \\\n",
       "0      ABC0174  gold negotiating 13 vice entry coach memorial ...   \n",
       "1      ABC0174  future always planets poorer jupiters only soo...   \n",
       "2      ABC0174  100 bruins eight 1997 intensive fan reprimande...   \n",
       "3      ABC0174  nhls 01 season teammate home minnesota win str...   \n",
       "4      ABC0174  naturally formed nuclei rising hours york expe...   \n",
       "...        ...                                                ...   \n",
       "15499  RVC0232  substantial last not not 120 received recover ...   \n",
       "15500  KAT0489  20 horizontally morning left inversion radiate...   \n",
       "15501  RGN0408  led regarded personal low man smashing lot par...   \n",
       "15502  MAE0331  have ukraine be pron money terminally more fre...   \n",
       "15503  IYB0918  offices inch alec load 1999 i delaware birthda...   \n",
       "\n",
       "       num_recipients  hour  day_of_week  attachments   size  threat_flag  \\\n",
       "0                   1    14            5            0  19677         True   \n",
       "1                   3    14            5            0  23739         True   \n",
       "2                   1    14            5            0  25277         True   \n",
       "3                   2    14            5            0  40514         True   \n",
       "4                   4    14            5            0  20614         True   \n",
       "...               ...   ...          ...          ...    ...          ...   \n",
       "15499               2    17            0            0  76284        False   \n",
       "15500               4    17            0            2  21608        False   \n",
       "15501               2    17            0            1  27696        False   \n",
       "15502               2    17            0            0  32210        False   \n",
       "15503               2    19            0            0  28077        False   \n",
       "\n",
       "                                           cleaned_email  sentiment_score  \\\n",
       "0      gold negotiating vice entry coach memorial mid...           0.7096   \n",
       "1      future always planet poorer jupiter soon specu...          -0.6249   \n",
       "2      bruin eight intensive fan reprimanded corey mv...           0.8402   \n",
       "3      nhls season teammate home minnesota win streng...           0.8271   \n",
       "4      naturally formed nucleus rising hour york expe...          -0.0258   \n",
       "...                                                  ...              ...   \n",
       "15499  substantial last received recover enacted scal...           0.4939   \n",
       "15500  horizontally morning left inversion radiated l...           0.5677   \n",
       "15501  led regarded personal low man smashing lot par...          -0.5574   \n",
       "15502  ukraine pron money terminally fresh father goo...           0.7269   \n",
       "15503  office inch alec load delaware birthday freedo...           0.5106   \n",
       "\n",
       "       keyword_threat  anomaly  \n",
       "0               False    False  \n",
       "1                True     True  \n",
       "2               False     True  \n",
       "3               False     True  \n",
       "4               False    False  \n",
       "...               ...      ...  \n",
       "15499           False    False  \n",
       "15500           False    False  \n",
       "15501            True     True  \n",
       "15502           False    False  \n",
       "15503           False    False  \n",
       "\n",
       "[15504 rows x 12 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "554582c9-c083-410c-bc61-c80f0b7f8fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the data ()\n",
    "X = vectorizer.fit_transform(combined_data['cleaned_email'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "077dd03b-c349-4d05-93f5-f2a518facdce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5856175427281523\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.70      0.66      0.68      2051\n",
      "        True       0.40      0.44      0.42      1050\n",
      "\n",
      "    accuracy                           0.59      3101\n",
      "   macro avg       0.55      0.55      0.55      3101\n",
      "weighted avg       0.60      0.59      0.59      3101\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train-test split (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = LogisticRegression(class_weight='balanced', random_state=42,max_iter=500)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ad38bea8-ef99-46e5-830a-abcf54feba2c",
   "metadata": {},
   "source": [
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot confusion matrix using seaborn\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"False\", \"True\"], yticklabels=[\"False\", \"True\"])\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e88927cb-4d5d-4cad-9643-c33f0523b6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 0.1, 'class_weight': 'balanced', 'max_iter': 4000, 'solver': 'saga'}\n",
      "Accuracy: 0.5869074492099323\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.70      0.66      0.68      2051\n",
      "        True       0.40      0.45      0.43      1050\n",
      "\n",
      "    accuracy                           0.59      3101\n",
      "   macro avg       0.55      0.55      0.55      3101\n",
      "weighted avg       0.60      0.59      0.59      3101\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'C': [0.1],\n",
    "    'solver': ['liblinear', 'saga'],\n",
    "    'class_weight': ['balanced', None],\n",
    "    'max_iter': [4000]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(LogisticRegression(random_state=42), param_grid, cv=5, scoring='f1_macro')\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid.best_params_)\n",
    "model = grid.best_estimator_\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8968e0d9-70b1-4b67-8aea-df952f2090e7",
   "metadata": {},
   "source": [
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot confusion matrix using seaborn\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"False\", \"True\"], yticklabels=[\"False\", \"True\"])\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa64503c-49dd-49eb-83e9-97fd2c8f3c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters from Logistic Regression GridSearchCV: {'C': 0.1, 'class_weight': 'balanced', 'max_iter': 4000, 'solver': 'saga'}\n",
      "Accuracy: 0.344727507255724\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.85      0.01      0.02      2051\n",
      "        True       0.34      1.00      0.51      1050\n",
      "\n",
      "    accuracy                           0.34      3101\n",
      "   macro avg       0.60      0.50      0.26      3101\n",
      "weighted avg       0.68      0.34      0.19      3101\n",
      "\n",
      "ROC AUC Score: 0.5651974646513895\n"
     ]
    }
   ],
   "source": [
    "# Extracting best parameters from grid search\n",
    "best_params = grid.best_params_\n",
    "print(\"Best Parameters from Logistic Regression GridSearchCV:\", best_params)\n",
    "\n",
    "# Adjusted class weights based on logistic regression\n",
    "pos_weight = len(y_train[y_train == 0]) / len(y_train[y_train == 1])\n",
    "\n",
    "# XGBoost model with additional hyperparameters tuned\n",
    "xgb_model = XGBClassifier(\n",
    "    scale_pos_weight=pos_weight,\n",
    "    random_state=42,\n",
    "    learning_rate=0.1,  \n",
    "    max_depth=6,  #\n",
    "    n_estimators=100,  \n",
    "    objective='binary:logistic',  \n",
    "    eval_metric='logloss'  \n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "y_prob = xgb_model.predict_proba(X_test)[:, 1]\n",
    "threshold = 0.3  \n",
    "y_pred = (y_prob > threshold).astype(int)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_test, y_prob))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4b6a8c31-7050-4d82-8e1c-b1884d5aaed8",
   "metadata": {},
   "source": [
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot confusion matrix using seaborn\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"False\", \"True\"], yticklabels=[\"False\", \"True\"])\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d95437f5-fc96-4f89-94de-2d8204cc1f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6091583360206385\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.69      0.75      0.72      2051\n",
      "        True       0.41      0.34      0.37      1050\n",
      "\n",
      "    accuracy                           0.61      3101\n",
      "   macro avg       0.55      0.54      0.54      3101\n",
      "weighted avg       0.59      0.61      0.60      3101\n",
      "\n"
     ]
    }
   ],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e84f7339-d9d1-4b22-ade8-77d73dc51a9f",
   "metadata": {},
   "source": [
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot confusion matrix using seaborn\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"False\", \"True\"], yticklabels=[\"False\", \"True\"])\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65a1b70-a662-4945-99e9-93677e66e9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorization\n",
    "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2), stop_words='english')\n",
    "X = vectorizer.fit_transform(combined_data['cleaned_email'])\n",
    "\n",
    "# Scaling \n",
    "scaler = StandardScaler(with_mean=False)\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Handle class imbalance with SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_scaled, y)\n",
    "\n",
    "# Logistic Regression GridSearchCV\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10],\n",
    "    'solver': ['liblinear', 'saga'],\n",
    "    'class_weight': ['balanced', None],\n",
    "    'max_iter': [5000, 10000]  # Increase max_iter even further\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(LogisticRegression(random_state=42), param_grid, cv=5, scoring='f1_macro')\n",
    "grid.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Best Logistic Regression Model\n",
    "lr_model = grid.best_estimator_\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# XGBoost Classifier\n",
    "pos_weight = len(y_train[y_train == 0]) / len(y_train[y_train == 1])  # Handle class imbalance\n",
    "xgb_model = XGBClassifier(\n",
    "    scale_pos_weight=pos_weight,\n",
    "    random_state=42,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    n_estimators=300,\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "xgb_model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    verbose=False  \n",
    ")\n",
    "\n",
    "# Optimal Threshold for XGBoost\n",
    "y_prob = xgb_model.predict_proba(X_test)[:, 1]\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_prob)\n",
    "f1_scores = 2 * (precision * recall) / (precision + recall)\n",
    "optimal_threshold = thresholds[np.argmax(f1_scores)]\n",
    "print(\"Optimal Threshold:\", optimal_threshold)\n",
    "\n",
    "# Predict with optimal threshold\n",
    "y_pred = (y_prob > optimal_threshold).astype(int)\n",
    "\n",
    "# Logistic Regression Evaluation\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "print(\"\\n=== Logistic Regression Evaluation ===\")\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred_lr))\n",
    "print(\"Logistic Regression Report:\\n\", classification_report(y_test, y_pred_lr))\n",
    "print(\"Logistic Regression Report:\\n\", confusion_matrix(y_test, y_pred_lr))\n",
    "\n",
    "# Ensemble with VotingClassifier\n",
    "ensemble_model = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('lr', lr_model),\n",
    "        ('xgb', xgb_model)\n",
    "    ],\n",
    "    voting='soft'  # Use soft voting for probabilities\n",
    ")\n",
    "ensemble_model.fit(X_resampled, y_resampled)\n",
    "y_pred_ensemble = ensemble_model.predict(X_test)\n",
    "\n",
    "print(\"\\n=== Ensemble Evaluation ===\")\n",
    "print(\"Ensemble Accuracy:\", accuracy_score(y_test, y_pred_ensemble))\n",
    "print(\"Ensemble Classification Report:\\n\", classification_report(y_test, y_pred_ensemble))\n",
    "print(\"Ensemble Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_ensemble))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f51e6d8b-c390-43cb-ba07-3eb3b95b4a90",
   "metadata": {},
   "source": [
    "#random_users = pd.Series(non_insider_users).sample(n=42, random_state=42)\n",
    "Ensemble (VotingClassifier)\n",
    "Accuracy: 88.08%\n",
    "Ensemble Classification Report:\n",
    "               precision    recall  f1-score   support\n",
    "\n",
    "       False       0.87      0.89      0.88      1034\n",
    "        True       0.89      0.87      0.88      1055\n",
    "\n",
    "    accuracy                           0.88      2089\n",
    "   macro avg       0.88      0.88      0.88      2089\n",
    "weighted avg       0.88      0.88      0.88      2089\n",
    "F1-Score (Macro Avg): 0.88\n",
    "Precision/Recall: Balanced across both classes.\n",
    "Performance: The ensemble method achieves the best performance overall, \n",
    "combining the strengths of logistic regression and XGBoost."
   ]
  },
  {
   "cell_type": "raw",
   "id": "90a0e297-49b1-412b-ae88-2af9d46eb3eb",
   "metadata": {},
   "source": [
    "#random_users = pd.Series(non_insider_users).sample(n=70, random_state=42)\n",
    "Optimal Threshold: 0.8239438\n",
    "\n",
    "=== Logistic Regression Evaluation ===\n",
    "Logistic Regression Accuracy: 0.801354401805869\n",
    "Logistic Regression Report:\n",
    "               precision    recall  f1-score   support\n",
    "\n",
    "       False       0.84      0.86      0.85      2051\n",
    "        True       0.72      0.69      0.70      1050\n",
    "\n",
    "    accuracy                           0.80      3101\n",
    "   macro avg       0.78      0.77      0.78      3101\n",
    "weighted avg       0.80      0.80      0.80      3101\n",
    "\n",
    "\n",
    "=== Ensemble Evaluation ===\n",
    "Ensemble Accuracy: 0.8103837471783296\n",
    "Ensemble Classification Report:\n",
    "               precision    recall  f1-score   support\n",
    "\n",
    "       False       0.86      0.86      0.86      2051\n",
    "        True       0.72      0.72      0.72      1050\n",
    "\n",
    "    accuracy                           0.81      3101\n",
    "   macro avg       0.79      0.79      0.79      3101\n",
    "weighted avg       0.81      0.81      0.81      3101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defd49ef-81d0-49fb-b47b-465ed7e60060",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred_lr, display_labels=['False', 'True'])\n",
    "plt.title(\"Logistic Regression Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred_ensemble, display_labels=['False', 'True'])\n",
    "plt.title(\"Ensemble Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d627d418-8c20-4792-bd08-fe3ea7407e82",
   "metadata": {},
   "source": [
    "## Feature select to idenfity threat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a00840-2e49-49d6-8cc5-3c340ad5eccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add other feature to identify possible threats\n",
    "features = ['num_recipients', 'hour', 'day_of_week','attachments', 'size' \\\n",
    "                           ,'sentiment_score', 'keyword_threat','anomaly']\n",
    "X_feature = combined_data[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394718ce-5f71-4dd9-b405-fa5390125349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_feature, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "model = LogisticRegression(class_weight='balanced', random_state=42,solver='lbfgs', max_iter=4000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1cbb9506-f44d-4b4f-aaa4-78891ef17ba9",
   "metadata": {},
   "source": [
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot confusion matrix using seaborn\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"False\", \"True\"], yticklabels=[\"False\", \"True\"])\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d599aa6a-16ca-4446-b8db-75feef6163c7",
   "metadata": {},
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "}\n",
    "\n",
    "# Grid Search\n",
    "grid_search = GridSearchCV(RandomForestClassifier(random_state=42, class_weight='balanced'),\n",
    "                           param_grid, cv=5, scoring='f1', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "best_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35837ecd-05df-4f83-823d-053241cceacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_feature, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train the Random Forest model\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=4,\n",
    "    class_weight='balanced',  \n",
    "    random_state=42\n",
    ")\n",
    "rf_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\nAccuracy Score:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe29dd2-adbd-411c-84d7-48a50cd92cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid for XGboost\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],      # Number of trees\n",
    "    'max_depth': [4, 6, 8],             # Depth of each tree\n",
    "    'learning_rate': [0.01, 0.1, 0.2],  # Step size for updates\n",
    "    'subsample': [0.8, 1.0],            # Fraction of samples per tree\n",
    "    'colsample_bytree': [0.8, 1.0],     # Fraction of features per tree\n",
    "    'scale_pos_weight': [1, pos_weight] # Adjusting class imbalance\n",
    "}\n",
    "\n",
    "# Initialize the XGBoost classifier\n",
    "xgb_model = XGBClassifier(random_state=42)\n",
    "\n",
    "# GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring='roc_auc', # Evaluating using AUC-ROC\n",
    "    cv=5,              # 5-fold cross-validation\n",
    "    verbose=1,\n",
    "    n_jobs=-1          # Use all available processors\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best ROC AUC Score:\", grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3753fd7c-ff16-4416-bba4-feb8f619cdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid_search.best_params_\n",
    "xgb_best_model = XGBClassifier(**best_params, random_state=42)\n",
    "xgb_best_model.fit(X_train, y_train)\n",
    "new_threshold = 0.32\n",
    "\n",
    "# Evaluate\n",
    "y_prob = xgb_best_model.predict_proba(X_test)[:, 1]\n",
    "y_pred = (y_prob > new_threshold).astype(int)  \n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\nROC AUC Score:\", roc_auc_score(y_test, y_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24318021-36bc-43b4-aec1-38d6b7e69f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importances\n",
    "feature_importances = rf_model.feature_importances_\n",
    "sorted_idx = np.argsort(feature_importances)[::-1]\n",
    "sorted_features = [features[i] for i in sorted_idx]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(range(len(sorted_features)), feature_importances[sorted_idx], align='center')\n",
    "plt.yticks(range(len(sorted_features)), sorted_features)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Random Forest Feature Importances')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f07e871-9ebc-4b51-8d6e-afebae446bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
